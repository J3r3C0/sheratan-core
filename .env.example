# LLM Configuration for Worker
# Uncomment and configure one of the following:

# Option 1: LM Studio (local)
# SHERATAN_LLM_BASE_URL=http://host.docker.internal:1234/v1/chat/completions
# SHERATAN_LLM_MODEL=your-model-name
# SHERATAN_LLM_API_KEY=

# Option 2: Ollama (local)
# SHERATAN_LLM_BASE_URL=http://host.docker.internal:11434/v1/chat/completions
# SHERATAN_LLM_MODEL=llama2
# SHERATAN_LLM_API_KEY=

# Option 3: OpenAI
# SHERATAN_LLM_BASE_URL=https://api.openai.com/v1/chat/completions
# SHERATAN_LLM_MODEL=gpt-4
# SHERATAN_LLM_API_KEY=sk-...

# Option 4: WebRelay (ChatGPT via Browser)
SHERATAN_LLM_BASE_URL=http://host.docker.internal:3000/api/relay
# SHERATAN_LLM_MODEL=chatgpt
# SHERATAN_LLM_API_KEY=

# If no LLM is configured, worker will use static fallback plan
