# ğŸš€ Quick Start - Autonomen Loop testen

## Voraussetzung: Docker Desktop starten

âš ï¸ **Docker Desktop ist aktuell nicht gestartet.**

Bitte starte Docker Desktop, bevor du fortfÃ¤hrst.

---

## Test-Anleitung

### 1ï¸âƒ£ System starten

```bash
cd c:\Sheratan\2_sheratan_core
docker-compose up --build
```

**Erwartete Ausgabe:**
```
âœ“ core        Started
âœ“ worker      Started  
âœ“ backend     Started
âœ“ frontend    Started
âœ“ webrelay    Started
```

---

### 2ï¸âƒ£ Dashboard Ã¶ffnen

Browser Ã¶ffnen und navigieren zu:
```
http://localhost:8001/control-dashboard.html
```

Falls Port 8001 nicht erreichbar:
- Core lÃ¤uft auf Port **8001**
- Alternativ kannst du auch direkt die Datei Ã¶ffnen:
  ```
  file:///c:/Sheratan/2_sheratan_corecontrol-dashboard.html
  ```
  Und manuell auf `http://localhost:8001` konfigurieren

---

### 3ï¸âƒ£ Test-Prompt eingeben

Im Dashboard in die Textarea eingeben:

```
Analyze Python files in /workspace/project
```

Dann auf **"Send to WebRelay"** klicken.

---

### 4ï¸âƒ£ Erwartetes Verhalten

**Dashboard:**
1. Zeigt "â³ Creating mission and calling LLM..." an
2. Wartet ~30 Sekunden
3. Zeigt Response mit Follow-up Jobs:
   ```
   âœ… Response Received
   
   Action: create_followup_jobs
   Commentary: First list all Python files, then read main.py...
   Followup Jobs: 2
   
   Jobs created:
     1. [âœ“ auto] List Python files (list_files)
        Params: {"root": "/workspace/project", "patterns": ["**/*.py"]}
     2. [â—‹ manual] Read main.py (read_file)
        Params: {"root": "/workspace/project", "rel_path": "main.py"}
   ```

**Was im Hintergrund passiert:**
1. Dashboard erstellt Mission
2. Erstellt Task mit `kind: "agent_plan"`
3. Erstellt & dispatched Job
4. Worker empfÃ¤ngt Job â†’ ruft LLM auf
5. LLM gibt LCP-konformes JSON zurÃ¼ck
6. Worker validiert & schreibt Result
7. Core sync'd Result
8. Dashboard zeigt Result an

**ğŸ¯ Wenn Auto-Dispatch funktioniert:**
- Follow-up Job "List Python files" wird automatisch ausgefÃ¼hrt
- Du kannst weitere Follow-up Results sehen

---

### 5ï¸âƒ£ Logs Ã¼berprÃ¼fen

In einem zweiten Terminal:

```bash
cd c:\Sheratan\2_sheratan_core
docker-compose logs -f worker core
```

**Erwartete Log-Patterns:**

**Worker:**
```
[worker] Processing job file ... (job_id=...)
[worker] handle_job job_id=... task_kind=agent_plan
[worker] Calling LLM at http://...
[worker] âœ“ Valid LCP response: action=create_followup_jobs, jobs=2
[worker] Wrote result file ...
```

**Core (wenn LCP Interpreter aktiv):**
```
[lcp_actions] Task 'list_files' not found in mission, creating it...
[lcp_actions] Created task: ... (kind=list_files)
ğŸ“ Followup job created and queued: ... (kind=list_files, name=List Python files)
```

---

## âš ï¸ Troubleshooting

### Problem: LLM gibt falsches Format

**Symptom:**
```
[worker] ERROR: Job ... missing required 'kind' field (use 'kind', not 'task')
```

**Ursache:** LLM ignoriert Prompt-Anweisungen

**LÃ¶sung:**
- PrÃ¼fe `SHERATAN_LLM_BASE_URL` in `.env`
- Teste mit strikterem Modell (z.B. GPT-4 statt GPT-3.5)
- Aktiviere `response_format: {type: "json_object"}` (nur OpenAI)

### Problem: Keine Follow-up Jobs werden erstellt

**Symptom:** Dashboard zeigt Response, aber keine Jobs in Logs

**Ursache:** `auto_dispatch: false` oder Backend-Issue

**LÃ¶sung:**
1. PrÃ¼fe ob `apply_agent_plan` aufgerufen wurde
2. Manuell dispatchen Ã¼ber API:
   ```bash
   curl -X POST http://localhost:8001/api/jobs/{job_id}/dispatch
   ```

### Problem: Docker Compose startet nicht

**Symptom:** Service-Fehler beim Start

**LÃ¶sung:**
```bash
# Services neu bauen
docker-compose down
docker-compose build --no-cache
docker-compose up
```

---

## âœ… Erfolgs-Kriterien

Der autonome Loop ist **erfolgreich repariert**, wenn:

1. âœ… Dashboard erstellt Mission ohne Fehler
2. âœ… Worker empfÃ¤ngt Job und ruft LLM auf
3. âœ… LLM gibt valides LCP JSON zurÃ¼ck (`kind`, `name`, `params`)
4. âœ… Worker validiert erfolgreich (Log: `âœ“ Valid LCP response`)
5. âœ… Core erstellt Follow-up Tasks & Jobs
6. âœ… Follow-up Jobs mit `auto_dispatch: true` werden automatisch ausgefÃ¼hrt
7. âœ… Logs zeigen `ğŸ“ Followup job created and queued`

---

## ğŸ“Š NÃ¤chste Optimierungen (Optional)

Nach erfolgreichem Test:

1. **JSON Schema Validation** hinzufÃ¼gen fÃ¼r noch strengere Format-PrÃ¼fung
2. **Monitoring Metriken** fÃ¼r Follow-up Job Erfolgsrate
3. **Doppelte Follow-up Logik** konsolidieren (Core vs Backend)
4. **Rate Limiting** fÃ¼r LLM Calls implementieren
5. **Retry Logic** fÃ¼r fehlgeschlagene Jobs

---

## ğŸ‰ Viel Erfolg beim Testen!

Der Loop sollte jetzt sauber funktionieren ğŸš€
